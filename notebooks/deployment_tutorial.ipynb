{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DINOv3 Deployment Tutorial\n",
                "\n",
                "This tutorial guides you through exporting a DINOv3 model to ONNX format and running inference using ONNX Runtime. This is essential for deploying models to edge devices or production environments where Python availability might be restricted."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import onnxruntime as ort\n",
                "from dinov3production import create_model\n",
                "from dinov3production.deploy.exporter import EdgeExporter\n",
                "\n",
                "model_name = 'dinov3_vits14'\n",
                "print(f\"Using model: {model_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Export to ONNX\n",
                "Create the model and use `EdgeExporter` to convert it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = create_model(model_name, pretrained=True).eval()\n",
                "exporter = EdgeExporter(model)\n",
                "\n",
                "onnx_path = f'{model_name}.onnx'\n",
                "exporter.to_onnx(onnx_path)\n",
                "print(f\"Model exported to {onnx_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Inference with ONNX Runtime\n",
                "Now we verify the exported model by running inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create ONNX Runtime Session\n",
                "session = ort.InferenceSession(onnx_path)\n",
                "\n",
                "# Create Dummy Input\n",
                "# ONNX expects numpy arrays\n",
                "input_name = session.get_inputs()[0].name\n",
                "input_shape = session.get_inputs()[0].shape\n",
                "# Handle dynamic shapes if needed, usually [Batch, 3, H, W]\n",
                "fake_input = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
                "\n",
                "# Run Inference\n",
                "outputs = session.run(None, {input_name: fake_input})\n",
                "\n",
                "# Outputs is a list of results corresponding to output nodes\n",
                "output_tensor = outputs[0]\n",
                "print(f\"Output Shape: {output_tensor.shape}\")\n",
                "\n",
                "# Compare with PyTorch output\n",
                "with torch.no_grad():\n",
                "    torch_out = model(torch.from_numpy(fake_input))\n",
                "    \n",
                "# Check Mean Squared Error\n",
                "mse = np.mean((output_tensor - torch_out.numpy())**2)\n",
                "print(f\"MSE between ONNX and PyTorch: {mse:.6f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}